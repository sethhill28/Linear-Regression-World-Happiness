{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preperation\n",
    "The purpose of this notebook is to showcase the process that was undertaken to clean and prepare the data to be fed into a linear regression model. Further preperation may be required when building the categorical models in future parts of the project.\n",
    "\n",
    "I began the process by importing the required libraries and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "y1 = pd.read_csv('Data/2015.csv')\n",
    "y2 = pd.read_csv('Data/2016.csv')\n",
    "y3 = pd.read_csv('Data/2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since many processes will have to be repeated for all three files I will defined some usefull functions to avoiding having to repeat myself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column(df, col, val):\n",
    "    df[col] = val\n",
    "    \n",
    "def remove_puncuation(df):\n",
    "    '''Removes puncuation from column names based off regular expressions'''\n",
    "    new_cols = []\n",
    "    for col in df.columns:\n",
    "        col = re.sub('[.!#?,:;]', '', col)\n",
    "        new_cols.append(col)\n",
    "        \n",
    "    df.columns = new_cols\n",
    "    \n",
    "def clean_columns(df, ops):\n",
    "    '''Performs user defined operations across all columns'''\n",
    "    new_columns = []\n",
    "    columns = list(df.columns)\n",
    "    for col in columns:\n",
    "        for function in ops:\n",
    "            col = function(col)\n",
    "        new_columns.append(col)\n",
    "        \n",
    "    df.columns = new_columns \n",
    "  \n",
    "#operations to be performed on columns\n",
    "clean_ops = [str.strip, str.title]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then checked for missing values and applied these functions on all three files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "y1.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add year column\n",
    "add_column(y1, 'Year', 2015)\n",
    "remove_puncuation(y1)\n",
    "clean_columns(y1, clean_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "y2.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add year columnn\n",
    "add_column(y2, 'Year', 2016)\n",
    "remove_puncuation(y2)\n",
    "clean_columns(y2, clean_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values\n",
    "y3.isnull().values.any() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add year column\n",
    "add_column(y3, 'Year', 2017)\n",
    "remove_puncuation(y3)\n",
    "clean_columns(y3, clean_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, none of the files contained any missing values. Making the data cleaning process much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating One Giant Data Frame \n",
    "Once the files were cleaned at a surface level, I began the process of manipulating them into structures that could be concatenated into one giant dataframe.\n",
    "\n",
    "To start, I created a datframe containing the column names into one giant dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_columns = pd.Series(y1.columns)\n",
    "y2_columns = pd.Series(y2.columns)\n",
    "y3_columns = pd.Series(y3.columns)\n",
    "\n",
    "all_columns = pd.DataFrame({'2015': (y1_columns), '2016': y2_columns, '2017': y3_columns})\n",
    "all_columns = all_columns.sort_values('2015')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I redefined the column names to meet a standardized format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.rename(columns = {'Year': 'Year',\n",
    "                     'Country': 'Country', \n",
    "                     'Economy (Gdp Per Capita)': 'GDP Per Capita', \n",
    "                     'Happiness Rank': 'Happiness Rank', \n",
    "                     'Happiness Score' : 'Happiness Score', \n",
    "                     'Health (Life Expectancy)': 'Life Expectancy', \n",
    "                     'Trust (Government Corruption)': 'Government Corruption', \n",
    "                     'Family': 'Family', \n",
    "                     'Freedom': 'Freedom', \n",
    "                     'Generosity': 'Generosity'\n",
    "                    }, inplace = True)\n",
    "\n",
    "y2.rename(columns = {'Year': 'Year', \n",
    "                     'Country': 'Country', \n",
    "                     'Economy (Gdp Per Capita)': 'GDP Per Capita', \n",
    "                     'Happiness Rank': 'Happiness Rank',\n",
    "                     'Happiness Score': 'Happiness Score', \n",
    "                     'Family': 'Family', \n",
    "                     'Health (Life Expectancy)': 'Life Expectancy', \n",
    "                     'Trust (Government Corruption)': 'Government Corruption', \n",
    "                     'Freedom': 'Freedom', \n",
    "                     'Generosity': 'Generosity' \n",
    "                    }, inplace = True)\n",
    "\n",
    "y3.rename(columns = {'Year': 'Year', \n",
    "                     'Country': 'Country', \n",
    "                     'Economygdppercapita' : 'GDP Per Capita', \n",
    "                     'Happinessrank': 'Happiness Rank', \n",
    "                     'Happinessscore': 'Happiness Score', \n",
    "                     'Family': 'Family', \n",
    "                     'Healthlifeexpectancy': 'Life Expectancy', \n",
    "                     'Trustgovernmentcorruption': 'Government Corruption', \n",
    "                     'Freedom': 'Freedom', \n",
    "                     'Generosity': 'Generosity'\n",
    "                    }, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the column names were all in a standardized format, I defined which column names to keep then created a function that drops all the columns that I did not make the cut and reorders the columns.\n",
    "\n",
    "Columns were selected based off similarity across the 3 datasets not preference or bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cols = ['Year', 'Country', 'GDP Per Capita', 'Happiness Rank', \n",
    "             'Happiness Score', 'Life Expectancy', 'Government Corruption', \n",
    "             'Family', 'Freedom', 'Generosity']\n",
    "\n",
    "def drop_columns(df, true_cols):\n",
    "    \"\"\"Drops columns we don't want from each data frame\"\"\"\n",
    "    drop_columns = []\n",
    "    for df_col in list(df.columns):\n",
    "        for true_col in true_cols:\n",
    "            if df_col not in true_cols:\n",
    "                drop_columns.append(df_col)\n",
    "    df.drop(columns = drop_columns, inplace = True)\n",
    "\n",
    "#Drop columns from each dataframe\n",
    "drop_columns(y1, true_cols)\n",
    "drop_columns(y2, true_cols)\n",
    "drop_columns(y3, true_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once all datframes were in the correct format. I concatenated them into one giant dataframe, reordered it based off the year the data was collected, then wrote it into a csv for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
